{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceeadb7a",
   "metadata": {},
   "source": [
    "大语言模型（LLM）是通过预测下一个词的监督学习方式进行训练的。具体来说，首先准备一个包含数百亿甚至更多词的大规模文本数据集。然后，可以从这些文本中提取句子或句子片段作为模型输入。模型会根据当前输入 Context 预测下一个词的概率分布。通过不断比较模型预测和实际的下一个词，并更新模型参数最小化两者差异,语言模型逐步掌握了语言的规律，学会了预测下一个词。\n",
    "\n",
    "在训练过程中,研究人员会准备大量句子或句子片段作为训练样本,要求模型一次次预测下一个词，通过反复训练促使模型参数收敛，使其预测能力不断提高。经过在海量文本数据集上的训练，语言模型可以达到十分准确地预测下一个词的效果。这种以预测下一个词为训练目标的方法使得语言模型获得强大的语言生成能力。\n",
    "\n",
    "大型语言模型主要可以分为两类:基础语言模型和指令调优语言模型。\n",
    "\n",
    "基础语言模型（Base LLM）通过反复预测下一个词来训练的方式进行训练，没有明确的目标导向。因此，如果给它一个开放式的 prompt ，它可能会通过自由联想生成戏剧化的内容。而对于具体的问题，基础语言模型也可能给出与问题无关的回答。例如，给它一个 Prompt ，比如”中国的首都是哪里？“，很可能它数据中有一段互联网上关于中国的测验问题列表。这时，它可能会用“中国最大的城市是什么？中国的人口是多少？”等等来回答这个问题。但实际上，您只是想知道中国的首都是什么，而不是列举所有这些问题。\n",
    "\n",
    "相比之下，指令微调的语言模型（Instruction Tuned LLM）则进行了专门的训练，以便更好地理解问题并给出符合指令的回答。例如，对“中国的首都是哪里？”这个问题，经过微调的语言模型很可能直接回答“中国的首都是北京”，而不是生硬地列出一系列相关问题。指令微调使语言模型更加适合任务导向的对话应用。它可以生成遵循指令的语义准确的回复，而非自由联想。因此，许多实际应用已经采用指令调优语言模型。熟练掌握指令微调的工作机制，是开发者实现语言模型应用的重要一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253d1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"sk-75d7f4d4d4f744fb925f0bf09c87c48b\"\n",
    "openai.api_base = \"https://api.deepseek.com\"\n",
    "# 下文第一个函数即tool工具包中的同名函数，此处展示出来以便于读者对比\n",
    "def get_completion(prompt, model=\"deepseek-chat\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # 控制模型输出的随机程度\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7960bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是**北京**。  \n",
      "北京是中国的政治、文化、国际交往和科技创新中心，也是中华人民共和国中央人民政府所在地。作为历史悠久的名城，北京拥有故宫、天坛、长城等世界文化遗产，同时也是一个现代化国际大都市。\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"中国的首都是哪里？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfd48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
